{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c2c77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\melih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "def split_data(data, ratio=0.7): # when the ratio argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the \n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = list(data)  \n",
    "    n = len(data)  \n",
    "    train_indices = random.sample(range(n), int(n * ratio))          \n",
    "    test_indices = list(set(range(n)) - set(train_indices))    \n",
    "    train = [data[i] for i in train_indices]           \n",
    "    test = [data[i] for i in test_indices]             \n",
    "    return (train, test)                       \n",
    "\n",
    "def get_train_test_data():\n",
    "    \n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "   \n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "   \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b824e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['the', 'summer', 'movie', 'season', 'is', 'always', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bfc4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#removal of digits, punctuation and stopwords\n",
    "puncts = string.punctuation\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "training_data = [([lemma.lemmatize(word) for word in doc if (word not in puncts and word not in stop_words and word.isalpha())],label) for doc,label in training_data]\n",
    "testing_data = [([lemma.lemmatize(word) for word in doc if (word not in puncts and word not in stop_words and word.isalpha())],label) for doc,label in testing_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1081771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_list_generator(training_data,list_length=10):\n",
    "    '''\n",
    "    A method to generate lists of given length from both tags which are positive and negative.\n",
    "    \n",
    "    :param training_data: data from which the lists will generated\n",
    "    :param list_length: the length of the lists\n",
    "    \n",
    "    :return: positive and negative word lists\n",
    "\n",
    "    '''    \n",
    "    training_freqs = [(FreqDist(doc),label) for doc,label in training_data]\n",
    "    pos_word_freqs = FreqDist()\n",
    "    neg_word_freqs = FreqDist()\n",
    "    \n",
    "    #finding out the frequencies of words in each category\n",
    "    for doc,label in training_freqs:\n",
    "        if label == 'pos':\n",
    "            pos_word_freqs += doc\n",
    "        else:\n",
    "            neg_word_freqs += doc\n",
    "            \n",
    "    #separation the pairs into two seperate lists\n",
    "    #single underscore here is used as a throw-away variable\n",
    "    pos_words, _ = zip(*pos_word_freqs.most_common(list_length))\n",
    "    neg_words, _ = zip(*neg_word_freqs.most_common(list_length))\n",
    "    \n",
    "    return pos_words, neg_words\n",
    "\n",
    "pos_words, neg_words = word_list_generator(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10153c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('film',\n",
       " 'one',\n",
       " 'movie',\n",
       " 'character',\n",
       " 'like',\n",
       " 'time',\n",
       " 'scene',\n",
       " 'make',\n",
       " 'story',\n",
       " 'get')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
